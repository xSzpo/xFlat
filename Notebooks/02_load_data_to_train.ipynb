{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import bson\n",
    "from bson.json_util import dumps, loads\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import PIL\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import geopandas\n",
    "import numpy as np\n",
    "import feather\n",
    "import h5py\n",
    "\n",
    "pd.options.display.max_columns=999\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import helper \n",
    "import sys\n",
    "sys.path.append(\"/Users/xszpo/Google Drive/DataScience/Projects/201907_xFlat_AWS_Scrapy\")\n",
    "import helpers\n",
    "\n",
    "# run scrapy settings\n",
    "%run /Users/xszpo/Google\\ Drive/DataScience/Projects/201907_xFlat_AWS_Scrapy/scraper/settings.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/xszpo/Google Drive/DataScience/DATA/01_otodom_scrapy'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOCAL_DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [i for i in os.listdir(LOCAL_DATA_PATH) if i.endswith(\".bson\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15821"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data frame\n",
    "\n",
    "def load_data(file_name_list, file_path):\n",
    "    \n",
    "    _tmp_list = [None for i in range(len(file_name_list))]\n",
    "    \n",
    "    for i,file in enumerate(file_name_list):\n",
    "        \n",
    "        # LOAD DATA\n",
    "        _tmp = helpers.scraper.read_bson_local(file_path, file)\n",
    "        _tmp = helpers.scraper.dict_except(_tmp,['img_gallery_strimg','gallery'])\n",
    "        \n",
    "        # PUT DATA INTO COLUMNS\n",
    "        _tmp['file_name'] = file\n",
    "        _tmp['GC_latitude'] = _tmp['geo_coordinates']['latitude']\n",
    "        _tmp['GC_llongitude'] = _tmp['geo_coordinates']['longitude']\n",
    "        _tmp['GC_boundingbox'] = _tmp['geo_address_coordin']['@boundingbox']\n",
    "        _tmp['GC_addr_house_number'] = _tmp['geo_address_text']['house_number'] if 'house_number' in _tmp['geo_address_text'] else None\n",
    "        _tmp['GC_addr_road'] = _tmp['geo_address_text']['road'] if 'road' in _tmp['geo_address_text'] else None\n",
    "        _tmp['GC_addr_neighbourhood'] = _tmp['geo_address_text']['neighbourhood'] if 'neighbourhood' in _tmp['geo_address_text'] else None\n",
    "        _tmp['GC_addr_suburb'] = _tmp['geo_address_text']['suburb'] if 'suburb' in _tmp['geo_address_text'] else None\n",
    "        _tmp['GC_addr_city'] = _tmp['geo_address_text']['city'] if 'city' in _tmp['geo_address_text'] else None\n",
    "        _tmp['GC_addr_county'] = _tmp['geo_address_text']['county'] if 'country' in _tmp['geo_address_text'] else None\n",
    "        _tmp['GC_addr_state'] = _tmp['geo_address_text']['state'] if 'state' in _tmp['geo_address_text'] else None\n",
    "        _tmp['GC_addr_postcode'] = _tmp['geo_address_text']['postcode'] if 'postcode' in _tmp['geo_address_text'] else None\n",
    "        _tmp['GC_addr_country'] = _tmp['geo_address_text']['country'] if 'country' in _tmp['geo_address_text'] else None\n",
    "        _tmp['GC_addr_country_code'] = _tmp['geo_address_text']['country_code'] if 'country_code' in _tmp['geo_address_text'] else None\n",
    "        _ = _tmp.pop('geo_coordinates')\n",
    "        _ = _tmp.pop('geo_address_coordin')\n",
    "        _ = _tmp.pop('price_per_square')\n",
    "\n",
    "        \n",
    "        # MODIFY DATA\n",
    "        _tmp['flat_size'] = helpers.scraper.digits_from_str(_tmp['flat_size']) if _tmp['flat_size'] is not None else None\n",
    "        _tmp['price'] = helpers.scraper.digits_from_str(_tmp['price']) if _tmp['price'] is not None else None\n",
    "        _tmp['price_m2'] = helpers.scraper.digits_from_str(_tmp['price_m2']) if _tmp['price_m2'] is not None else None\n",
    "        _tmp['rooms'] = int(helpers.scraper.digits_from_str(_tmp['rooms'])) if _tmp['rooms'] is not None else None\n",
    "        _tmp['floor_attic'] = 1 if _tmp['floor']=='poddasze' else 0\n",
    "        _tmp['floor_basement'] = 1 if _tmp['floor']=='suterena' else 0\n",
    "        _tmp['floor'] = np.float32(helpers.scraper.convert_floor(_tmp['floor'])) if isinstance(_tmp['floor'], (str)) else None\n",
    "        _tmp['number_of_floors'] = np.float32(_tmp['number_of_floors']) if isinstance(_tmp['number_of_floors'], (str)) else None\n",
    "        _tmp['year_of_building'] = np.float32(_tmp['year_of_building']) if isinstance(_tmp['year_of_building'], (str)) else None\n",
    "        _tmp['rent_price'] = helpers.scraper.digits_from_str(_tmp['rent_price']) if _tmp['rent_price'] is not None else None\n",
    "        \n",
    "        # SAVE TO LIST\n",
    "        _tmp_list[i] = _tmp\n",
    "        \n",
    "        columns = ['offer_id','tracking_id','name','location','flat_size', 'rooms','floor','price',\n",
    "                'price_m2', 'market', 'number_of_floors', 'floor_attic','floor_basement','building_type', \n",
    "                'building_material', 'widows_type', 'heating_type', 'year_of_building','finishing_stage', \n",
    "                'rent_price', 'property_form', 'available_from','description','additional_info',\n",
    "                'GC_latitude','GC_llongitude', 'GC_boundingbox', 'GC_addr_house_number','GC_addr_road', \n",
    "                'GC_addr_neighbourhood', 'GC_addr_suburb','GC_addr_city', 'GC_addr_county', 'GC_addr_state', \n",
    "                'GC_addr_postcode','GC_addr_country', 'GC_addr_country_code','url','main_url']\n",
    "    \n",
    "    return pd.DataFrame(_tmp_list)[columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = load_data(file_list,LOCAL_DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feather.write_dataframe(data_df, os.path.join(LOCAL_DATA_PATH_PREP,'train_data.feather'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 13s, sys: 10.7 s, total: 2min 24s\n",
      "Wall time: 2min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def load_data(file_name_list, file_path, img_size = (224, 224)):\n",
    "    \n",
    "    _tmp_list = [None for i in range(len(file_name_list))]\n",
    "    \n",
    "    for i,file in enumerate(file_name_list):\n",
    "\n",
    "        # LOAD DATA\n",
    "        _tmp = helpers.scraper.read_bson_local(file_path, file)\n",
    "        _tmp = helpers.scraper.dict_except(_tmp,include_keys=['price','img_gallery_strimg'])\n",
    "        \n",
    "        # PUT DATA INTO COLUMNS\n",
    "        _tmp['file_name'] = file\n",
    "        _tmp['price'] = helpers.scraper.digits_from_str(_tmp['price']) if _tmp['price'] is not None else None\n",
    "        _tmp['photo_1'] = helpers.scraper.open_img_from_str(_tmp['img_gallery_strimg'][0]).resize(img_size) if len(_tmp['img_gallery_strimg'])>0 else None\n",
    "        _tmp['photo_2'] = helpers.scraper.open_img_from_str(_tmp['img_gallery_strimg'][1]).resize(img_size) if len(_tmp['img_gallery_strimg'])>1 is not None else None\n",
    "        _tmp['photo_3'] = helpers.scraper.open_img_from_str(_tmp['img_gallery_strimg'][2]).resize(img_size) if len(_tmp['img_gallery_strimg'])>2 is not None else None\n",
    "        _ = _tmp.pop('img_gallery_strimg')\n",
    "        \n",
    "        # SAVE TO LIST\n",
    "        _tmp_list[i] = _tmp\n",
    "        \n",
    "    return _tmp_list\n",
    "\n",
    "photo = load_data(file_list,LOCAL_DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []\n",
    "price = []\n",
    "\n",
    "for i in photo:\n",
    "    name += [i['file_name']]\n",
    "    price += [i['price']]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = np.array(name).reshape(-1,1)\n",
    "price = np.array(price).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.1 s, sys: 40.6 s, total: 1min 8s\n",
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "array_photo_1 = []\n",
    "array_photo_2 = []\n",
    "array_photo_3 = []\n",
    "\n",
    "for i in photo:\n",
    "    array_photo_1 += [image.img_to_array(i['photo_1']) if i['photo_1'] is not None else np.zeros((224, 224, 3))]\n",
    "    array_photo_2 += [image.img_to_array(i['photo_2']) if i['photo_2'] is not None else np.zeros((224, 224, 3))]\n",
    "    array_photo_3 += [image.img_to_array(i['photo_3']) if i['photo_3'] is not None else np.zeros((224, 224, 3))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "del(photo)\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_photo_1 = np.concatenate(array_photo_1).reshape(-1,224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_photo_2 = np.concatenate(array_photo_2).reshape(-1,224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_photo_3 = np.concatenate(array_photo_3).reshape(-1,224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://keras.io/getting-started/faq/#how-can-i-use-hdf5-inputs-with-keras    \n",
    "http://tdeboissiere.github.io/h5py-vs-npz.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "with h5py.File(os.path.join(LOCAL_DATA_PATH_PREP,'array_photo.h5'), \"w\") as hf:\n",
    "    dset = hf.create_dataset(\"array_photo_1\", data=array_photo_1, compression=\"gzip\")\n",
    "    dset = hf.create_dataset(\"array_photo_2\", data=array_photo_2, compression=\"gzip\")\n",
    "    dset = hf.create_dataset(\"array_photo_3\", data=array_photo_3, compression=\"gzip\")\n",
    "    dset = hf.create_dataset(\"name\", data=name, compression=\"gzip\", compression_opts=9)\n",
    "    dset = hf.create_dataset(\"price\", data=price, compression=\"gzip\", compression_opts=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(os.path.join(LOCAL_DATA_PATH_PREP,'array_photo'), \n",
    "                    a1=array_photo_1, a2=array_photo_2, a3=array_photo_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_scrapy",
   "language": "python",
   "name": "aws_scrapy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
