# docker exec -it <container> /bin/bash

version: '3.7'

services:

  mongo:
    #docker run -p 27017:27017 -e "MONGO_INITDB_DATABASE=OFFERS" -e "MONGO_INITDB_ROOT_USERNAME=<<>>" -e "MONGO_INITDB_ROOT_PASSWORD=<<>>" mongo
    image: mongo:4.2.0-bionic
    container_name: mongo
    restart: always
    env_file: ./secrets/mongo.env
    ports:
      - 27017:27017
    volumes:
      - ./mongodb/db:/data/db
    networks:
      - webnet

  redis:
    image: redis:buster
    container_name: redis
    restart: always
    env_file: ./secrets/mongo.env
    ports:
      - 6379:6379
    networks:
      - webnet

  zookeeper:
    image: wurstmeister/zookeeper:3.4.6
    container_name: zookeeper
    restart: always
    ports:
      - "2181:2181"
    networks:
      - webnet

  kafka:
    image: wurstmeister/kafka:2.12-2.3.0
    container_name: kafka
    restart: always
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: kafka
      KAFKA_CREATE_TOPICS: "otodom:1:1,olx:1:1,morizon:1:1,gratka:1:1"
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - webnet

  nifi:
    #image: apache/nifi:1.10.0
    build:
      context: ./nifi
      dockerfile: Dockerfile_nifi
    image: nifi_xflats:0.0.1
    container_name: nifi
    restart: always
    ports:
      - 9090:9090
    env_file: ./secrets/nifi.env
    environment:
      NIFI_WEB_HTTP_PORT: 9090
      MONGO_INITDB_DATABASE: OFFERS
    #volumes:
    #  - ./nifi/conf:/opt/nifi/nifi-current/conf
    networks:
      - webnet

  mlmodel:
    build: ./app_mlmodel
    container_name: mlmodel
    image: app_mlmodel:1.0.0
    restart: always
    ports:
      - 8666:8666
      - 8000:8000
    networks:
      - webnet

  scraper_otodom:
    build:
      context: ./app_web
      dockerfile: Dockerfile_otodom
    image: app_scraper_otodom:0.0.1
    container_name: scraper_otodom
    restart: always
    volumes:
      - ./app_web/scraper/settings.py:/app/scraper/settings.py
      - ./app_web/scraper/spiders/xhpats.json:/app/scraper/spiders/xhpats.json
    env_file: ./secrets/scraper.env
    environment:
      SCRAPER_START_DELAY_SEC: 180
      SCRAPER_DELAY_AFTER_EACH_RUN_SEC: 180
    depends_on:
      - mongo
      - zookeeper
      - kafka
      - redis
    networks:
      - webnet

  scraper_olx:
    build:
      context: ./app_web
      dockerfile: Dockerfile_olx
    image: app_scraper_olx:0.0.1
    container_name: scraper_olx
    restart: always
    volumes:
      - ./app_web/scraper/settings.py:/app/scraper/settings.py
      - ./app_web/scraper/spiders/xhpats.json:/app/scraper/spiders/xhpats.json
    env_file: ./secrets/scraper.env
    environment:
      SCRAPER_START_DELAY_SEC: 180
      SCRAPER_DELAY_AFTER_EACH_RUN_SEC: 180
    depends_on:
      - mongo
      - zookeeper
      - kafka
      - redis
    networks:
      - webnet

  scraper_gratka:
    build:
      context: ./app_web
      dockerfile: Dockerfile_gratka
    image: app_scraper_gratka:0.0.1
    container_name: scraper_gratka
    restart: always
    volumes:
      - ./app_web/scraper/settings.py:/app/scraper/settings.py
      - ./app_web/scraper/spiders/xhpats.json:/app/scraper/spiders/xhpats.json
    env_file: ./secrets/scraper.env
    environment:
      SCRAPER_START_DELAY_SEC: 180
      SCRAPER_DELAY_AFTER_EACH_RUN_SEC: 180
    depends_on:
      - mongo
      - zookeeper
      - kafka
      - redis
    networks:
      - webnet

  scraper_morizon:
    build:
      context: ./app_web
      dockerfile: Dockerfile_morizon
    image: app_scraper_morizon:0.0.1
    container_name: scraper_morizon
    restart: always
    volumes:
      - ./app_web/scraper/settings.py:/app/scraper/settings.py
      - ./app_web/scraper/spiders/xhpats.json:/app/scraper/spiders/xhpats.json
    env_file: ./secrets/scraper.env
    environment:
      SCRAPER_START_DELAY_SEC: 180
      SCRAPER_DELAY_AFTER_EACH_RUN_SEC: 180
    depends_on:
      - mongo
      - zookeeper
      - kafka
      - redis
    networks:
      - webnet

networks:
  webnet:
